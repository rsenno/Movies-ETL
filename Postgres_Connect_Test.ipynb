{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "from config import db_password\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tom</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nick</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>juli</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name  Age\n",
       "0   tom   10\n",
       "1  nick   15\n",
       "2  juli   14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize list of lists\n",
    "data = [['tom', 10], ['nick', 15], ['juli', 14]]\n",
    "  \n",
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame(data, columns = ['Name', 'Age'])\n",
    "  \n",
    "# print dataframe.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the database engine connection\n",
    "db_string = f\"postgres://postgres:{db_password}@127.0.0.1:5432/movie_data\"\n",
    "# Create the engine\n",
    "engine = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(name='test', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Create the path to your file directory and variables for the three files.\n",
    "# pd.read_csv doesn't seem to like the file path specifications \n",
    "file_dir = 'Resources'\n",
    "# file_dir = '/Users/RobertEnno/Desktop/boot_camp/repo/modules/Movies-ETL/Resources'\n",
    "# The Wikipedia data\n",
    "wiki_file = f'{file_dir}/wikipedia-movies.json'\n",
    "# The Kaggle metadata\n",
    "kaggle_file = f'{file_dir}/movies_metadata.csv'\n",
    "# The MovieLens rating data.\n",
    "ratings_file = f'{file_dir}/ratings.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 0 to 1000000...Done. 162.72254347801208 total seconds elapsed\n",
      "importing rows 1000000 to 2000000...Done. 324.3850591182709 total seconds elapsed\n",
      "importing rows 2000000 to 3000000...Done. 489.0290057659149 total seconds elapsed\n",
      "importing rows 3000000 to 4000000...Done. 649.7583801746368 total seconds elapsed\n",
      "importing rows 4000000 to 5000000...Done. 810.4053676128387 total seconds elapsed\n",
      "importing rows 5000000 to 6000000...Done. 972.0071821212769 total seconds elapsed\n",
      "importing rows 6000000 to 7000000...Done. 1132.6948773860931 total seconds elapsed\n",
      "importing rows 7000000 to 8000000...Done. 1294.3256726264954 total seconds elapsed\n",
      "importing rows 8000000 to 9000000...Done. 1460.3961095809937 total seconds elapsed\n",
      "importing rows 9000000 to 10000000...Done. 1622.7427077293396 total seconds elapsed\n",
      "importing rows 10000000 to 11000000...Done. 1785.3368632793427 total seconds elapsed\n",
      "importing rows 11000000 to 12000000...Done. 1949.5246045589447 total seconds elapsed\n",
      "importing rows 12000000 to 13000000...Done. 2112.105890274048 total seconds elapsed\n",
      "importing rows 13000000 to 14000000...Done. 2273.0377204418182 total seconds elapsed\n",
      "importing rows 14000000 to 15000000...Done. 2451.01863861084 total seconds elapsed\n",
      "importing rows 15000000 to 16000000...Done. 2617.7128841876984 total seconds elapsed\n",
      "importing rows 16000000 to 17000000...Done. 2783.0482728481293 total seconds elapsed\n",
      "importing rows 17000000 to 18000000...Done. 2944.193170070648 total seconds elapsed\n",
      "importing rows 18000000 to 19000000...Done. 3109.011076927185 total seconds elapsed\n",
      "importing rows 19000000 to 20000000...Done. 3277.8151173591614 total seconds elapsed\n",
      "importing rows 20000000 to 21000000...Done. 3439.68967628479 total seconds elapsed\n",
      "importing rows 21000000 to 22000000...Done. 3609.304141521454 total seconds elapsed\n",
      "importing rows 22000000 to 23000000...Done. 3773.276341199875 total seconds elapsed\n",
      "importing rows 23000000 to 24000000...Done. 3939.320442676544 total seconds elapsed\n",
      "importing rows 24000000 to 25000000...Done. 4106.222719907761 total seconds elapsed\n",
      "importing rows 25000000 to 26000000...Done. 4272.518507480621 total seconds elapsed\n",
      "importing rows 26000000 to 26024289...Done. 4276.550492048264 total seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "# Import the Ratings Data\n",
    "rows_imported = 0\n",
    "# pd.read_csv doesn't seem to like the file path specifications \n",
    "file_dir = '/Users/RobertEnno/Desktop/boot_camp/repo/modules/Movies-ETL/Resources'\n",
    "# get the start_time from time.time()\n",
    "start_time = time.time()\n",
    "for data in pd.read_csv(f'{file_dir}/ratings.csv', chunksize=1000000):\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "    data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "    rows_imported += len(data)\n",
    "\n",
    "    # add elapsed time to final print out\n",
    "    print(f'Done. {time.time() - start_time} total seconds elapsed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
